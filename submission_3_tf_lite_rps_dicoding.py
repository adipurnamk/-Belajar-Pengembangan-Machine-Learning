# -*- coding: utf-8 -*-
"""Submission_3_TF_Lite_RPS_Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZKwmsh_GAQZOKQSpqZ9daFFeoTKFY0l8
"""

!pip install split-folders
!pip install split-folders tqdm
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

!wget --no-check-certificate \
  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

# melakukan ekstraksi pada file zip
import zipfile,os
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

os.listdir('/tmp')

import splitfolders

splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images', output="/tmp/rockpaperscissors/", seed=42, ratio=(.8, .2))

data_dir = '/tmp/rockpaperscissors/'
train_dir = os.path.join(data_dir, 'train')
validation_dir = os.path.join(data_dir, 'val')

# membuat direktori gunting, kertas dan batu pada direktori data training
train_clean_dir = os.path.join(train_dir, 'scissors')
train_messy_dir = os.path.join(train_dir, 'paper')
train_messy_dir = os.path.join(train_dir, 'rock')

# membuat direktori gunting, kertas dan batu pada direktori data validasi
validation_clean_dir = os.path.join(validation_dir, 'scissors')
validation_messy_dir = os.path.join(validation_dir, 'paper')
validation_messy_dir = os.path.join(validation_dir, 'rock')

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

train_generator = train_datagen.flow_from_directory(
        train_dir,  # direktori data latih
        target_size =(150,150),
        batch_size=32,
        # karena kita merupakan masalah klasifikasi 3 kelas maka menggunakan class_mode = 'categorical'
        class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
        validation_dir, # direktori data validasi
        target_size =(150,150),
        batch_size=32, 
        # karena kita merupakan masalah klasifikasi 3 kelas maka menggunakan class_mode = 'categorical'
        class_mode='categorical')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(8, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

# Model merupakan klasifikasi multi kelas sehingga loss function yang digunakan bukan binary_crossentropy.
from tensorflow.keras.callbacks import EarlyStopping

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

# Menambahkan early-stopping
es = EarlyStopping(monitor='val_loss', mode='min', verbose=2)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history = model.fit(
#             train_generator,
#             steps_per_epoch=25,  
#             epochs=20,
#             validation_data=validation_generator, 
#             validation_steps=5, 
#             callbacks=[es], 
#             verbose=2)

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Konversi model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

# Commented out IPython magic to ensure Python compatibility.
# Save the entire model to a HDF5 file.
# The '.h5' extension indicates that the model should be saved to HDF5.
model.save('my_model.pb') 
# %cd